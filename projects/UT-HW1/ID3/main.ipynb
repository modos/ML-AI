{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import Libraries",
   "id": "55b37194a855e8e0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-25T06:28:27.079059Z",
     "start_time": "2024-10-25T06:28:23.401529Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T06:28:54.225500Z",
     "start_time": "2024-10-25T06:28:54.213661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ID3DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, criterion=\"information_gain\"):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_sample(sample, self.tree) for _, sample in X.iterrows()])\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if len(y) == 0:\n",
    "            return None \n",
    "        if depth == self.max_depth or len(set(y)) == 1 or len(X) < self.min_samples_split:\n",
    "            return np.bincount(y).argmax()\n",
    "\n",
    "        best_feature, best_threshold = self._find_best_split(X, y)\n",
    "\n",
    "        if best_feature is None:\n",
    "            return np.bincount(y).argmax() \n",
    "\n",
    "        # Create a decision node\n",
    "        left_index = X[best_feature] < best_threshold\n",
    "        right_index = X[best_feature] >= best_threshold\n",
    "\n",
    "        left_subtree = self._build_tree(X[left_index], y[left_index], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_index], y[right_index], depth + 1)\n",
    "\n",
    "        return {best_feature: {best_threshold: left_subtree, \"else\": right_subtree}}\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        best_gain = -float(\"inf\")\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature in X.columns:\n",
    "            thresholds = X[feature].unique()\n",
    "            for threshold in thresholds: \n",
    "                gain = self._calculate_gain(X, y, feature, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold \n",
    "\n",
    "    def _calculate_gain(self, X, y, feature, threshold):\n",
    "        if self.criterion == \"information_gain\":\n",
    "            return self._information_gain(X, y, feature, threshold)\n",
    "        elif self.criterion == \"information_gain_ratio\":\n",
    "            return self._information_gain_ratio(X, y, feature, threshold)\n",
    "        elif self.criterion == \"gini_index\":\n",
    "            return self._gini_index(X, y, feature, threshold)\n",
    "\n",
    "    def _information_gain(self, X, y, feature, threshold):\n",
    "        total_entropy = self._entropy(y)\n",
    "        left_index = X[feature] < threshold\n",
    "        right_index = X[feature] >= threshold\n",
    "\n",
    "        left_entropy = self._entropy(y[left_index])\n",
    "        right_entropy = self._entropy(y[right_index])\n",
    "\n",
    "        weighted_left_entropy = len(y[left_index]) / len(y) * left_entropy\n",
    "        weighted_right_entropy = len(y[right_index]) / len(y) * right_entropy\n",
    "\n",
    "        return total_entropy - (weighted_left_entropy + weighted_right_entropy)\n",
    "\n",
    "    def _information_gain_ratio(self, X, y, feature, threshold):\n",
    "        information_gain = self._information_gain(X, y, feature, threshold)\n",
    "        intrinsic_value = self._entropy(y)\n",
    "\n",
    "        if intrinsic_value == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return information_gain / intrinsic_value\n",
    "\n",
    "    def _gini_index(self, X, y, feature, threshold):\n",
    "        total_gini = self._gini(y)\n",
    "        left_index = X[feature] < threshold\n",
    "        right_index = X[feature] >= threshold\n",
    "\n",
    "        left_gini = self._gini(y[left_index])\n",
    "        right_gini = self._gini(y[right_index])\n",
    "\n",
    "        weighted_left_gini = len(y[left_index]) / len(y) * left_gini\n",
    "        weighted_right_gini = len(y[right_index]) / len(y) * right_gini\n",
    "\n",
    "        return total_gini - (weighted_left_gini + weighted_right_gini)\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        value_counts = np.bincount(y)\n",
    "        probabilities = value_counts / len(y)\n",
    "        probabilities = probabilities[probabilities > 0]\n",
    "        return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "    def _gini(self, y):\n",
    "        value_counts = np.bincount(y)\n",
    "        probabilities = value_counts / len(y)\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "    def _predict_sample(self, sample, tree):\n",
    "        if isinstance(tree, dict):\n",
    "            feature = next(iter(tree))\n",
    "            thresholds = tree[feature]\n",
    "            threshold = next(iter(thresholds))\n",
    "        \n",
    "            if sample[feature] is None:\n",
    "                return 0 \n",
    "\n",
    "            if sample[feature] < threshold:\n",
    "                return self._predict_sample(sample, thresholds[threshold])\n",
    "            else:\n",
    "                return self._predict_sample(sample, thresholds[\"else\"])\n",
    "        else:\n",
    "            return tree\n"
   ],
   "id": "a0cf549522df631b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T06:28:57.719423Z",
     "start_time": "2024-10-25T06:28:57.707909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"titanic.csv\")\n",
    "data=  data.drop(data.columns[0], axis=1)\n",
    "data[\"age\"] = data[\"age\"].fillna(data[\"age\"].mean())\n",
    "data[\"embarked\"] = data[\"embarked\"].fillna(data[\"embarked\"].mode()[0])\n",
    "\n",
    "\n",
    "data['fare_bin'] = pd.qcut(data['fare'], 4, labels=False)\n",
    "data = data.drop('fare', axis=1)\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"sex\"] = label_encoder.fit_transform(data[\"sex\"])\n",
    "data[\"embarked\"] = label_encoder.fit_transform(data[\"embarked\"])\n",
    "\n",
    "X = data.drop(\"survived\", axis=1)\n",
    "y = data[\"survived\"]"
   ],
   "id": "fbe2cdab4f59b02c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T06:28:59.794258Z",
     "start_time": "2024-10-25T06:28:59.788727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)"
   ],
   "id": "88b7ea0e338b83db",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T06:29:18.440073Z",
     "start_time": "2024-10-25T06:29:02.015526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_params = {}\n",
    "best_f1 = 0\n",
    "results = []\n",
    "\n",
    "for max_depth in [3, 5, 9, 11]:\n",
    "    for min_samples_split in [2, 10, 30, 40]:\n",
    "        for criterion in [\"information_gain\", \"information_gain_ratio\", \"gini_index\"]:\n",
    "            tree = ID3DecisionTree(max_depth=max_depth, min_samples_split=min_samples_split, criterion=criterion)\n",
    "            tree.fit(X_train, y_train)\n",
    "            y_pred_val = tree.predict(X_val)\n",
    "            f1 = f1_score(y_val, y_pred_val)\n",
    "            results.append([criterion, max_depth, min_samples_split, f1])\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_params = {\"max_depth\": max_depth, \"min_samples_split\": min_samples_split, \"criterion\": criterion}\n",
    "                best_f1 = f1\n",
    "\n",
    "with open(\"results.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    fieldnames = [\"criterion\", \"max_depth\", \"min_samples_split\", \"f1_score\"]\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(fieldnames)\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(\"Best parameters:\", best_params)"
   ],
   "id": "fa9f8cd85fbaa457",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 9, 'min_samples_split': 10, 'criterion': 'gini_index'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T06:29:47.503529Z",
     "start_time": "2024-10-25T06:29:18.450485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tree = ID3DecisionTree(**best_params)\n",
    "\n",
    "best_test_f1 = 0\n",
    "best_test_accuracy = 0\n",
    "for max_depth in [3, 5, 9, 11]:\n",
    "    for min_samples_split in [2, 10, 30, 40]:\n",
    "        for criterion in [\"information_gain\", \"information_gain_ratio\", \"gini_index\"]:\n",
    "            tree = ID3DecisionTree(max_depth=max_depth, min_samples_split=min_samples_split, criterion=criterion)\n",
    "            tree.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "            y_pred = tree.predict(X_test)\n",
    "            y_pred = np.nan_to_num(y_pred)\n",
    "            y_pred = y_pred.astype(float)\n",
    "            y_pred = np.nan_to_num(y_pred, nan=0)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if f1 > best_test_f1:\n",
    "                best_test_f1 = f1\n",
    "            if accuracy > best_test_accuracy:\n",
    "                best_test_accuracy = accuracy\n",
    "            print(\"max_depth: \", max_depth, \"min_samples_split: \", min_samples_split, \"f1_score: \", f1, \"accuracy: \", accuracy)"
   ],
   "id": "9bd384901b4b909c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth:  3 min_samples_split:  2 f1_score:  0.640625 accuracy:  0.6783216783216783\n",
      "max_depth:  3 min_samples_split:  2 f1_score:  0.640625 accuracy:  0.6783216783216783\n",
      "max_depth:  3 min_samples_split:  2 f1_score:  0.6896551724137931 accuracy:  0.7482517482517482\n",
      "max_depth:  3 min_samples_split:  10 f1_score:  0.640625 accuracy:  0.6783216783216783\n",
      "max_depth:  3 min_samples_split:  10 f1_score:  0.640625 accuracy:  0.6783216783216783\n",
      "max_depth:  3 min_samples_split:  10 f1_score:  0.6896551724137931 accuracy:  0.7482517482517482\n",
      "max_depth:  3 min_samples_split:  30 f1_score:  0.640625 accuracy:  0.6783216783216783\n",
      "max_depth:  3 min_samples_split:  30 f1_score:  0.640625 accuracy:  0.6783216783216783\n",
      "max_depth:  3 min_samples_split:  30 f1_score:  0.6896551724137931 accuracy:  0.7482517482517482\n",
      "max_depth:  3 min_samples_split:  40 f1_score:  0.640625 accuracy:  0.6783216783216783\n",
      "max_depth:  3 min_samples_split:  40 f1_score:  0.640625 accuracy:  0.6783216783216783\n",
      "max_depth:  3 min_samples_split:  40 f1_score:  0.6896551724137931 accuracy:  0.7482517482517482\n",
      "max_depth:  5 min_samples_split:  2 f1_score:  0.7017543859649122 accuracy:  0.7622377622377622\n",
      "max_depth:  5 min_samples_split:  2 f1_score:  0.7017543859649122 accuracy:  0.7622377622377622\n",
      "max_depth:  5 min_samples_split:  2 f1_score:  0.7070707070707071 accuracy:  0.7972027972027972\n",
      "max_depth:  5 min_samples_split:  10 f1_score:  0.7017543859649122 accuracy:  0.7622377622377622\n",
      "max_depth:  5 min_samples_split:  10 f1_score:  0.7017543859649122 accuracy:  0.7622377622377622\n",
      "max_depth:  5 min_samples_split:  10 f1_score:  0.693069306930693 accuracy:  0.7832167832167832\n",
      "max_depth:  5 min_samples_split:  30 f1_score:  0.6422018348623854 accuracy:  0.7272727272727273\n",
      "max_depth:  5 min_samples_split:  30 f1_score:  0.6422018348623854 accuracy:  0.7272727272727273\n",
      "max_depth:  5 min_samples_split:  30 f1_score:  0.7058823529411765 accuracy:  0.7902097902097902\n",
      "max_depth:  5 min_samples_split:  40 f1_score:  0.6422018348623854 accuracy:  0.7272727272727273\n",
      "max_depth:  5 min_samples_split:  40 f1_score:  0.6422018348623854 accuracy:  0.7272727272727273\n",
      "max_depth:  5 min_samples_split:  40 f1_score:  0.7058823529411765 accuracy:  0.7902097902097902\n",
      "max_depth:  9 min_samples_split:  2 f1_score:  0.7128712871287128 accuracy:  0.7972027972027972\n",
      "max_depth:  9 min_samples_split:  2 f1_score:  0.7128712871287128 accuracy:  0.7972027972027972\n",
      "max_depth:  9 min_samples_split:  2 f1_score:  0.74 accuracy:  0.8181818181818182\n",
      "max_depth:  9 min_samples_split:  10 f1_score:  0.6857142857142857 accuracy:  0.7692307692307693\n",
      "max_depth:  9 min_samples_split:  10 f1_score:  0.6857142857142857 accuracy:  0.7692307692307693\n",
      "max_depth:  9 min_samples_split:  10 f1_score:  0.7047619047619048 accuracy:  0.7832167832167832\n",
      "max_depth:  9 min_samples_split:  30 f1_score:  0.6470588235294118 accuracy:  0.7482517482517482\n",
      "max_depth:  9 min_samples_split:  30 f1_score:  0.6470588235294118 accuracy:  0.7482517482517482\n",
      "max_depth:  9 min_samples_split:  30 f1_score:  0.6833333333333333 accuracy:  0.7342657342657343\n",
      "max_depth:  9 min_samples_split:  40 f1_score:  0.6666666666666666 accuracy:  0.7552447552447552\n",
      "max_depth:  9 min_samples_split:  40 f1_score:  0.6666666666666666 accuracy:  0.7552447552447552\n",
      "max_depth:  9 min_samples_split:  40 f1_score:  0.7058823529411765 accuracy:  0.7902097902097902\n",
      "max_depth:  11 min_samples_split:  2 f1_score:  0.7090909090909091 accuracy:  0.7762237762237763\n",
      "max_depth:  11 min_samples_split:  2 f1_score:  0.7090909090909091 accuracy:  0.7762237762237763\n",
      "max_depth:  11 min_samples_split:  2 f1_score:  0.7184466019417476 accuracy:  0.7972027972027972\n",
      "max_depth:  11 min_samples_split:  10 f1_score:  0.6896551724137931 accuracy:  0.7482517482517482\n",
      "max_depth:  11 min_samples_split:  10 f1_score:  0.6896551724137931 accuracy:  0.7482517482517482\n",
      "max_depth:  11 min_samples_split:  10 f1_score:  0.6915887850467289 accuracy:  0.7692307692307693\n",
      "max_depth:  11 min_samples_split:  30 f1_score:  0.6538461538461539 accuracy:  0.7482517482517482\n",
      "max_depth:  11 min_samples_split:  30 f1_score:  0.6538461538461539 accuracy:  0.7482517482517482\n",
      "max_depth:  11 min_samples_split:  30 f1_score:  0.6833333333333333 accuracy:  0.7342657342657343\n",
      "max_depth:  11 min_samples_split:  40 f1_score:  0.6666666666666666 accuracy:  0.7552447552447552\n",
      "max_depth:  11 min_samples_split:  40 f1_score:  0.6666666666666666 accuracy:  0.7552447552447552\n",
      "max_depth:  11 min_samples_split:  40 f1_score:  0.7058823529411765 accuracy:  0.7902097902097902\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T06:30:46.031256Z",
     "start_time": "2024-10-25T06:30:46.028468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(best_test_accuracy)\n",
    "print(best_test_f1)"
   ],
   "id": "cf7a878d80c43fdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n",
      "0.74\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
